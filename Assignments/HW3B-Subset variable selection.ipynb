{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "corporate-opportunity",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_boston\n",
    "from random import sample\n",
    "import random\n",
    "random.seed(14023799)\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import statsmodels.formula.api as smf\n",
    "import statsmodels.api as sm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cellular-parent",
   "metadata": {},
   "source": [
    "### Boston Housing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "foster-pittsburgh",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_boston()\n",
    "boston_housing = pd.DataFrame(dataset.data, columns= map(str.lower, dataset.feature_names))\n",
    "boston_housing['medv'] = dataset.target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sunset-colony",
   "metadata": {},
   "source": [
    "### 2.2 Preparation\n",
    "#### 2.2.1 Splitting data to training and testing samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "chinese-reserve",
   "metadata": {},
   "outputs": [],
   "source": [
    "num = list(range(len(boston_housing)))\n",
    "ran = sample(num, int(len(num)*0.8))\n",
    "rem = [i for i in num if i not in ran] \n",
    "\n",
    "boston_train = boston_housing.iloc[ran, :]\n",
    "boston_test = boston_housing.iloc[rem, :]\n",
    "\n",
    "X_train = boston_train.iloc[:,:-1]\n",
    "y_train = boston_train.iloc[:,-1:]\n",
    "\n",
    "X_test = boston_test.iloc[:,:-1]\n",
    "y_test = boston_test.iloc[:,-1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "private-timeline",
   "metadata": {},
   "source": [
    "### 3.2 Best Subset Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "found-solomon",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5453f5dba77441ed94d0581919696161",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loop...:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def fit_linear_reg(X,Y):\n",
    "    #Fit linear regression model and return RSS and R squared values\n",
    "    model_k = LinearRegression(fit_intercept = True)\n",
    "    model_k.fit(X,Y)\n",
    "    RSS = mean_squared_error(Y, model_k.predict(X))*len(Y)\n",
    "    R_squared = model_k.score(X,Y)\n",
    "    return RSS, R_squared\n",
    "\n",
    "#Implementing Best subset selection (using itertools.combinations)Â¶\n",
    "#Importing tqdm for the progress bar\n",
    "from tqdm import tnrange, tqdm_notebook\n",
    "import itertools \n",
    "\n",
    "#Initialization variables\n",
    "Y = y_train['medv']\n",
    "X = X_train\n",
    "k = len(y_train.columns) + 1\n",
    "RSS_list, R_squared_list, feature_list = [],[],[]\n",
    "numb_features = []\n",
    "\n",
    "#Looping over k features in X\n",
    "for k in tnrange(1,len(X.columns) + 1, desc = 'Loop...'):\n",
    "\n",
    "    #Looping over all possible combinations: from 11 choose k\n",
    "    for combo in itertools.combinations(X.columns,k):\n",
    "        tmp_result = fit_linear_reg(X[list(combo)],Y)   #Store temp result \n",
    "        RSS_list.append(tmp_result[0])                  #Append lists\n",
    "        R_squared_list.append(tmp_result[1])\n",
    "        feature_list.append(combo)\n",
    "        numb_features.append(len(combo))   \n",
    "\n",
    "#Store in DataFrame\n",
    "df_f = pd.DataFrame({'numb_features': numb_features,'RSS': RSS_list, \n",
    "                   'R_squared':R_squared_list,'features':feature_list})   \n",
    "\n",
    "#Finding the best subsets for each number of features\n",
    "#Using the smallest RSS value, or the largest R_squared value\n",
    "\n",
    "df_min = df_f[df_f.groupby('numb_features')['RSS'].transform(min) == df_f['RSS']]\n",
    "df_max = df_f[df_f.groupby('numb_features')['R_squared'].transform(max) == df_f['R_squared']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "rural-forestry",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('crim', 'zn', 'nox', 'rm', 'dis', 'rad', 'tax', 'ptratio', 'b', 'lstat')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_max.iloc[9,3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "worse-reproduction",
   "metadata": {},
   "source": [
    "### 3.3 Forward/Backward/Stepwise Regression Using AIC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acknowledged-circular",
   "metadata": {},
   "source": [
    "#### 3.3.1 Backward Elimination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pursuant-valuation",
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward_elimination(data, target):\n",
    "    \n",
    "    best_features = data.columns.tolist()\n",
    "    \n",
    "    aic = sm.OLS(target, sm.add_constant(data[best_features])).fit().aic\n",
    "    aic_values = [aic]\n",
    "\n",
    "    while (True):\n",
    "        new_aic = pd.Series(index = best_features)\n",
    "        aic_diff = pd.Series(index = best_features)\n",
    "        \n",
    "        for new_column in best_features:\n",
    "            model = sm.OLS(target, sm.add_constant(data[list(set(best_features) - set([new_column]))])).fit()\n",
    "            new_aic[new_column] = model.aic\n",
    "            aic_diff[new_column] = aic - model.aic\n",
    "            \n",
    "        max_aic = aic_diff.max()\n",
    "        \n",
    "        if(max_aic > 0):\n",
    "            best_features.remove(aic_diff.idxmax())\n",
    "            aic = new_aic[aic_diff.idxmax()]\n",
    "            aic_values.append(aic)\n",
    "            \n",
    "        else:\n",
    "            break\n",
    "    \n",
    "    final_AIC = sm.OLS(target, sm.add_constant(data[list(best_features)])).fit().aic\n",
    "    \n",
    "    return best_features, final_AIC\n",
    "\n",
    "print('The variable coefficients provided by the model are:')\n",
    "print(backward_elimination(X_train, y_train)[0])\n",
    "print('\\nFinal AIC value for the model is:')\n",
    "print(backward_elimination(X_train, y_train)[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "boolean-transfer",
   "metadata": {},
   "source": [
    "#### 3.3.2 Forward Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "korean-organization",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_selection(data, target):\n",
    "    \n",
    "    initial_features = data.columns.tolist()\n",
    "    best_features = []\n",
    "    \n",
    "    aic = sm.OLS(target, sm.add_constant(data[best_features])).fit().aic\n",
    "    aic_values = [aic]\n",
    "    \n",
    "    while (len(initial_features) > 0):\n",
    "        remaining_features = list(set(initial_features) - set(best_features))\n",
    "        new_aic = pd.Series(index = remaining_features)\n",
    "        \n",
    "        for new_column in remaining_features:\n",
    "            model = sm.OLS(target, sm.add_constant(data[best_features+[new_column]])).fit()\n",
    "            new_aic[new_column] = model.aic\n",
    "        min_aic = new_aic.min()\n",
    "        \n",
    "        if(min_aic < aic):\n",
    "            aic = min_aic\n",
    "            aic_values.append(aic)\n",
    "            best_features.append(new_aic.idxmin())\n",
    "        else:\n",
    "            break\n",
    "    \n",
    "    final_AIC = sm.OLS(target, sm.add_constant(data[list(best_features)])).fit().aic\n",
    "    \n",
    "    return best_features, final_AIC\n",
    "\n",
    "print('The variable coefficients provided by the model are:')\n",
    "print(forward_selection(X_train, y_train)[0])\n",
    "print('\\nFinal AIC value for the model is:')\n",
    "print(forward_selection(X_train, y_train)[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "medium-sharing",
   "metadata": {},
   "source": [
    "### Bi-directional elimination(Stepwise Selection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adverse-manufacturer",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stepwise_selection(data, target):\n",
    "    \n",
    "    initial_features = data.columns.tolist()\n",
    "    best_features = []\n",
    "    \n",
    "    aic = sm.OLS(target, sm.add_constant(data[best_features])).fit().aic\n",
    "    \n",
    "    while (len(initial_features) > 0):\n",
    "        remaining_features = list(set(initial_features) - set(best_features))\n",
    "        forw_aic = pd.Series(index = remaining_features)\n",
    "        \n",
    "        for new_column in remaining_features:\n",
    "            model = sm.OLS(target, sm.add_constant(data[best_features+[new_column]])).fit()\n",
    "            forw_aic[new_column] = model.aic\n",
    "        min_aic = forw_aic.min()\n",
    "        \n",
    "        if(min_aic < aic):\n",
    "            aic = min_aic\n",
    "            best_features.append(forw_aic.idxmin())\n",
    "\n",
    "            while (True):\n",
    "                \n",
    "                aic = sm.OLS(target, sm.add_constant(data[best_features])).fit().aic\n",
    "                \n",
    "                back_aic = pd.Series(index = best_features)\n",
    "                aic_diff = pd.Series(index = best_features)\n",
    "\n",
    "                for new_column in best_features:\n",
    "                    model = sm.OLS(target, sm.add_constant(data[list(set(best_features) - set([new_column]))])).fit()\n",
    "                    back_aic[new_column] = model.aic\n",
    "                    aic_diff[new_column] = aic - model.aic\n",
    "\n",
    "                max_aic = aic_diff.max()\n",
    "\n",
    "                if(max_aic > 0):\n",
    "                    best_features.remove(aic_diff.idxmax())\n",
    "                    aic = back_aic[aic_diff.idxmax()]\n",
    "                else:\n",
    "                    break\n",
    "                \n",
    "        else:\n",
    "            break\n",
    "    \n",
    "    final_AIC = sm.OLS(target, sm.add_constant(data[list(best_features)])).fit().aic\n",
    "    return best_features, final_AIC\n",
    "\n",
    "print('The variable coefficients provided by the model are:')\n",
    "print(stepwise_selection(X_train, y_train)[0])\n",
    "\n",
    "print('\\nFinal AIC value for the model is:')\n",
    "print(stepwise_selection(X_train, y_train)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "periodic-jewelry",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
